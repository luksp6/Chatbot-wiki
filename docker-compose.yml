services:
  wiki_chatbot:
    build:
      context: .
      dockerfile: Dockerfile.chatbot
      args:
        - GITHUB_TOKEN=${GITHUB_TOKEN}
        - REPO_OWNER=${REPO_OWNER}
        - REPO_NAME=${REPO_NAME}
        - CHATBOT_PORT=${CHATBOT_PORT}
    ports:
      - "${CHATBOT_PORT}:${CHATBOT_PORT}"
    environment:
      - CHATBOT_PORT=${CHATBOT_PORT}
      - REPO_NAME=${REPO_NAME}
      - GITHUB_TOKEN=${GITHUB_TOKEN}
      - REPO_OWNER=${REPO_OWNER}
      - DB_PATH=${DB_PATH}
      - COLLECTION_NAME=${COLLECTION_NAME}
      - EMBEDDING_NAME=${EMBEDDING_NAME}
      - LLM_NAME=${LLM_NAME}
      - MAX_BATCH_SIZE=${MAX_BATCH_SIZE}
      - CHUNK_SIZE=${CHUNK_SIZE}
      - CHUNK_OVERLAP=${CHUNK_OVERLAP}
      - PROMPT=${PROMPT}
    env_file:
      - ./chatbot/.env
    volumes:
      - ./chatbot:/app  # Monta el c√≥digo de tu proyecto en el contenedor
  weaviate:
    command:
    - --host
    - 0.0.0.0
    - --port
    - '8080'
    - --scheme
    - http
    image: cr.weaviate.io/semitechnologies/weaviate:1.29.0
    ports:
    - 8080:8080
    - 50051:50051
    volumes:
    - weaviate_data:/var/lib/weaviate
    restart: on-failure:0
    environment:
      QUERY_DEFAULTS_LIMIT: 25
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'
      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'
      ENABLE_API_BASED_MODULES: 'true'
      ENABLE_MODULES: 'text2vec-ollama,generative-ollama'
      CLUSTER_HOSTNAME: 'node1'
volumes:
  weaviate_data: